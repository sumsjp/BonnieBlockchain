 And so the world has fundamentally changed. These are going to be really important in the coming years. While Taiwan doesn't just build supercomputers for the world, today I'm very happy to announce that we're also building AI for Taiwan. I know that right now when we say there's an intelligence infrastructure, it makes no sense. But I promise you, in 10 years' time you will look back and you will realize that AI has now integrated into everything. The modern computer is an entire data center. The data center is a unit of computing. No longer just the PC, no longer just the server, the entire data center. Human or robot, it is likely to be the next multi-trillion dollar industry. Say it with me, the more you buy, the more you make. But just please buy something from me. I'm very pleased to announce that Nvidia Constellation will be at Beitou Xilin. And I have some surprises for you, things that you probably wouldn't have guessed. I just came out of the talk at the 2025 Nvidia Computex conference. Today is very special, Huang Renxun's parents are here too. Every year we participate online, and translate online, and give everyone a lot of essence. This time we were invited, thank you GeForce, the rest of Asia Pacific, Fred, for inviting us. I'm so happy, because everyone knows that I love Huang Renxun so much. This conference is very exciting, Huang Renxun announced that his personal super computer, if you want it, you can get it this Christmas, so please support it. Nvidia and Tairi will be doing the basic construction of AI in Taiwan, and Nvidia will set up a new office in Beitou Xilin. In this episode, Huang Renxun will tell you what he said at the GTC conference. He said that by 2030, there will be 30 million to 50 million jobs in the world. These jobs will all be done by AI. And you know, before, the chips were small, but now the latest chips are super huge. This episode is really exciting, it will subvert all your imagination about AI and technology. We have made a lot of essence for you, enjoy. It's great to be here. My parents are also in the audience. My parents are here, where are they? They're up there. Nvidia has been coming to Taiwan for over 30 years. This is the home of many of our treasured partners and dear friends. Over the years, you have seen Nvidia grow up and seen us accomplish many exciting things and have been partnered with me all along the way. Today we're going to talk about where we are in the industry, where we're going to go, announce some new products, exciting new products and surprising products that open new markets for us, creates new markets, new growth. We're going to talk about great partners and how we're going to develop this ecosystem together. As you know, we are at the epicenter of the computer ecosystem, one of the most important industries of the world. And so it stands to reason when new markets have to be created, we have to create it starting here, at the center of the computer ecosystem. And I have some surprises for you, things that you probably wouldn't have guessed. And then of course, I promise I'll talk about AI. And we'll talk about robotics. The Nvidia story is the reinvention of the computer industry. In fact, the Nvidia story is also the reinvention of our company. As I said, I've been coming here for 30 years. Many of you have been through many of my keynotes, some of you, all of them. And just as you reflect on the conversation, the things we talked about in the last 30 years, how dramatically changed. We started out as a chip company with a goal of creating a new computing platform. And in 2006, we introduced CUDA, which has revolutionized how computing is done. In 2016, 10 years later, we realized that a new computing approach has arrived. And this new computing approach requires a reinvention of every single layer of the technology stack. The processor is new, the software stack is new, it stands to reason the system is new. And so we invented a new system, a new system that on the day I announced it at GTC 2006, no one understood what I was talking about and nobody gave me a PO. That system was called DGX1. DGX1, I donated the first one to a nonprofit company called OpenAI. And it started the AI revolution. Years later, we realized that in fact, this new way of doing software, which is now called artificial intelligence, is unlike traditional ways of running software. Whereas many applications ran on a few processors in a large data center, we call that hyper scale. This new type of application requires many processors working together, serving queries for millions of people. And that data center would be architected fundamentally different. We realized there were two types of networks. One for north-south, because you still have to control the storage, you still have to have a control plane, you still have to connect to the outside. But the most important network was going to be east-west. The computers talking to each other to try to solve a problem. We recognized the best networking company in east-west traffic for high performance computing, large scale distributed processing, a company that was very dear to our company and very close to our heart, a company called Mellanox, and we bought them five years ago, 2019. We converted an entire data center into one computing unit. And you heard me say before, the modern computer is an entire data center. The data center is a unit of computing. No longer just a PC, no longer just a server, the entire data center is running one job. And the operating system would change. NVIDIA's data center journey is now very well known. Over the last three years, you've seen some of the ideas that we're shaping and how we are starting to see our company differently. No company in history, surely no technology company in history, has ever revealed a roadmap for five years at a time. No one would tell you what is coming next. They keep it as a secret, extremely confidential. However, we realized that NVIDIA is not a technology company only anymore. In fact, we are an essential infrastructure company. And how can you plan your infrastructure, your land, your shell, your power, your electricity, all of the necessary financing around all over the world? How would you possibly do that if you didn't understand what I was going to make? And so we described our company's roadmap in fair detail, enough detail that everybody in the world can go off and start building data centers. We realize now we are an AI infrastructure company, an infrastructure company that's essential all around the world. Every region, every industry, every company will build these infrastructures. And what are these infrastructures? These infrastructures, in fact, not unlike the first industrial revolution when people realized GE, Westinghouse, Siemens, realized that there was a new type of technology called electricity. And new infrastructure has to be built all around the world. And these infrastructure became essential part of social infrastructure. That infrastructure is now called electricity. Years later, this is during all of our generation, we realized there was a new type of infrastructure. And this new infrastructure was very conceptual, very hard to understand. And this infrastructure called information. This information infrastructure, the first time it was described, made no sense to anybody. But we now realized it is the Internet. And every Internet is everywhere and everything is connected to it. Well, there's a new infrastructure now. This new infrastructure is built on top of the first two. And this new infrastructure is an infrastructure of intelligence. I know that right now when we say there's an intelligence infrastructure, it makes no sense. But I promise you, in 10 years' time you will look back and you will realize that AI has now integrated into everything. And in fact, we need AI everywhere. And every region, every industry, every country, every company, all needs AI. AI has now part of infrastructure. And this infrastructure, just like the Internet, just like electricity, needs factories. And these factories are essentially what we build today. They're not data centers of the past, a $1 trillion industry providing information and storage, supporting all of our ERP systems and our employees. That's a data center, a data center of the past. This is similar in the sense that it came from the same industry. It came from all of us. But it's going to emerge as something completely different, completely separated from the world's data center. And these AI data centers, if you will, are improperly described. They are, in fact, AI factories. You apply energy to it, and it produces something incredibly valuable. And these things are called tokens. To the point where companies are starting to talk about how many tokens they produced last quarter and how many tokens they produced last month. Very soon, we'll be talking about how many tokens we produce every hour, just as every single factory does. And so the world has fundamentally changed. We went from a company, on the day that we started our company, I was trying to figure out how big our opportunity was in 1993, and I came to the conclusion, NVIDIA's business opportunity was enormous. $300 million. We're going to be rich. $300 million chip industry to a data center opportunity that represents about a trillion dollars, to now an AI factory, an AI infrastructure industry that will be measured in trillions of dollars. And this is the exciting future that we're undertaking. Now, at its core, everything we do is founded on several important technologies. Of course, I talk about accelerated computing a great deal. I talk about AI a great deal. What makes NVIDIA really special is the fusion of these capabilities. And very especially, very especially, the algorithms, the libraries, what we call the CUDA-X libraries. We're talking about libraries all the time. And in fact, we're the only technology company in the world that talks about libraries nonstop. And the reason for that is because libraries is at the core of everything that we do. You know, when you're CEO, you have many children. And GeForce brought us here. And now, all of our keynotes is 90% not GeForce. But it's not because we don't love GeForce. GeForce RTX 50 series just had its most successful launch ever, the fastest launch in our history. And PC gaming is now 30 years old. So that tells you something about how incredible GeForce is. Let's talk about libraries. At the core, of course, everything starts with CUDA. And by making CUDA as performant as possible, as pervasive as possible, so that the install base is all over the world, the more libraries, more amazing things are done, better applications, more benefits to users, they buy more computers. The more computers, more CUDA. That feedback path is vitally important. So the libraries themselves is what makes it possible for us, one domain of application after another domain of science, after another domain of physics, to be able to accelerate those applications. GPUs could be used for pre-processing and post-processing, for error correction, for control. And so in the future, I predict that all supercomputers will have quantum accelerators. All have quantum QPUs connected to it. And so a supercomputer would be a QPU with QPUs and GPUs and some CPUs. And that would be the representation of a modern computer. Generative AI gave us one-shot AI. You give a text and it gives you text back. You have now agentic AI. This agentic AI just does something that I've just described all of us do. We're given a goal, we break it down step by step, we reason about what to do, what's the best way to do it, we consider its consequences, and then we start executing the plan. The plan might include doing some research, might include doing some work, using some tools, it might include reaching out to another AI agent to collaborate with it. Agentic AI is basically understand, think, and act. Well, understand, think, and act is the robotics loop. Agentic AI is basically a robot in a digital form. These are going to be really important in the coming years. We're seeing enormous progress in this area. The next wave beyond that is physical AI. To be able to reason about these physical things is really essential to the next era of AI. We call that physical AI. So what used to be one-shot AI is now going to be thinking AI, reasoning AI, inference time scaling AI. And that's going to take a lot more computation. And so we created a new system called Grace Blackwell. Grace Blackwell does several things. It has the ability to scale up. Scale up means to turn what is a computer into a giant computer. Scale out is to take a computer and connect many of them together and let the work be done in many different computers. In Q3 of this year, just as I promised, every single year, we will increase the performance of our platform every single year like Rhythm. And this year in Q3, we'll upgrade to Grace Blackwell GB300. The GB300 will increase the same architecture, same physical footprint, same electrical mechanicals. But the chips inside have been upgraded. It has upgraded with a new Blackwell chip. It's now one and a half times more inference performance. It has one and a half times more HBM memory. And it has two times more networking. And so the overall system performance is higher. There's only a limit to how fast you can make chips and how big you can make chips. In the case of Blackwell, we even connected two chips together to make it possible. TSMC worked with us to invent a new co-op process called Co-op L that made it possible for us to create these giant chips. But still, we want chips way bigger than that. And so we had to create what is called MVLink. This is the world's fastest switch. This MVLink here, right here, is 7.2 terabytes per second. Nine of these go into that rack. And that nine, those nine switches are connected by this miracle. This is quite heavy. That's because I'm quite strong. I made it look so light, but this is almost 70 pounds. We now have the ability to disaggregate the GPUs out of one motherboard, essentially, across an entire rack. And so that entire rack is one motherboard. That's the miracle. Completely disaggregated, and now the GPU performance is incredible. The amount of memory is incredible. The networking bandwidth is incredible. And now we can really scale these out. Once we scale it up, then we can scale it out into large systems. And notice almost everything NVIDIA builds are gigantic. But really, in the end, we're not building data centers. We're building AI factories. And this is the XAI Colossus factory. This is Stargate. Four million square feet, four million square feet, one gigawatt. And so just think about this factory here. This one gigawatt factory is probably going to be about $60 to $80 billion. Out of that $60 to $80 billion, the electronics, the computing part of it, these systems are $40, $50 billion of it. And so these are gigantic factory investments. The reason why people build factories is because, say it with me, the more you buy, the more you make. That's what factories do. We couldn't be prouder of what we've achieved together. Thank you, Taiwan. Thank you. Thank you. That was pretty incredible, right? But that was you. That was you. Thank you. Well, Taiwan doesn't just build supercomputers for the world. Today, I'm very happy to announce that we're going to be building the first giant AI supercomputer here for the AI infrastructure and the AI ecosystem of Taiwan. And so today we're announcing the NVLink Fusion. And so we're going to be building the first giant AI supercomputer here for the AI infrastructure and the AI ecosystem of Taiwan. And so today we're announcing the NVLink Fusion. This incredible body of work now becomes flexible and open for everybody to integrate into. And so your AI infrastructure could have some NVIDIA, a lot of yours. A lot of yours, you know, and a lot of CPUs, a lot of ASICs, maybe a lot of NVIDIA GPUs as well. And so in any case, you have the benefit of using the NVLink infrastructure and the NVLink Fusion to build your own AI infrastructure and the NVLink ecosystem, and it's connected perfectly to SpectrumX. And all of that, you know, is industrial strength and has the benefit of an enormous ecosystem of industrial partners who have already made it possible. Now let me talk to you about some new product categories. As you know, I've shown you a couple of different computers. This new computer we call DGX Spark is in full production. We'll be ready, we'll be available shortly, probably in a few weeks, but you would just like to have your own, basically your own AI cloud sitting right next to you, and it's always on, always waiting for you. This is DGX1, this is 1 petaflops, and 128 gigabytes. Of course, this is 128 gigabytes of HBM memory, and this is 128 gigabytes of LPDDR5X. The performance is, in fact, quite similar. But what's most important is that the work that you could do, you could work on this, is the same work you could do here. One thing for sure, everybody can have one for Christmas. If that one isn't big enough for you, and this is going to be your own personal DGX supercomputer, this computer is the most performance you can possibly get out of a wall socket. You could put this in your kitchen, but just barely. If you put this in your kitchen and then somebody runs the microwave, I think this is the limit of what you can get out of a wall outlet, and this is a DGX station. A one trillion parameter model is going to run wonderfully on this machine. And the new capability for enterprise is agentic AI. Basically, digital marketing campaign manager, a digital researcher, a digital software engineer, digital customer service, digital chip designer, digital supply chain manager, digital versions, AI versions, of all of the work that we used to do. And as I mentioned earlier, agentic AI has the ability to reason, use tools, work with other AIs. So in a lot of ways, these are digital workers. They're digital employees. The world has a shortage of labor. We have a shortage of workers by 2030, by about 30 to 50 million shortage. It's actually limiting the world's ability to grow. And so now we have these digital agents that can work with us. 100% of NVIDIA software engineers now have digital agents working with them so that they can help them, assist them in developing better code and more productively. And so in the future, you're going to have this layer. That's our vision. You're going to have a layer of agentic AIs, AI agents. And so what's going to happen to the world? What's going to happen to enterprise? Whereas we have HR for human workers, we're going to have IT becoming the HR of digital workers. For today's IT industry, today's IT workers, to be able to manage, improve, evaluate a whole family of AI agents that are working inside their company. And so that's the vision of what we want to build. This is the brand new RTX Pro, RTX Pro Enterprise and Omniverse server. Omniverse runs on here perfectly. But in addition to that, in addition to that, this is the computer for enterprise AI agents. Those AI agents could be only text. Those AI agents could also be computer graphics. Little TJs coming to you, little toy Jensen's coming to see you, helping you do work. And so those AI agents could be either in text form, it could be in graphics form, it could be in video form. All of those workloads work on this system. The compute platform is different. The storage platform is different. And the reason for that is because humans query structured databases like SQL. But AI wants to query unstructured data. They want semantic. They want meaning. And so we have to create a new type of storage platform. It's because you need the system to embed, find the meaning in the unstructured data, in the raw data. You have to index, you have to do the search, and you do the ranking. So that process is very compute intensive. And so most storage servers in the future will have a GPU computing node in front of it. So agent AIs, agentic AIs, AI agents, a lot of different ways to say it, agents are essentially digital robots. The reason for that is because a robot perceives, understands, and plans. And that's essentially what agents do. But we would like to build also physical robots. And these physical robots, first, it starts with the ability to learn to be a robot. We're working on several things to help the robotics industry. Now you know that we've been working in autonomous systems for some time. Our self-driving car basically has three systems. There's the system for creating the AI model, and that's GB200, GB300. It's going to be used for that, training the AI model. Then you have Omniverse for simulating the AI model. And then when you're done with that AI model, you put that model, the AI, into the self-driving car. This year we're deploying Mercedes around the world, our self-driving car stack, end-to-end stack. We want to make sure that we provide our technology in a way that makes it as easy as possible for everybody to integrate NVIDIA's technology. You know, like I said, I love it if you buy everything from me, but just please buy something from me. Very practical. And so today we're announcing that Isaac Groot N1.5 is now open-sourced, and it's open to the world to use. It's been downloaded 6,000 times already, but human or robot, it is likely to be the next multi-trillion-dollar industry. And the technology innovation is incredibly fast, and the consumption of computing and data centers enormous. But this is one of those applications that needs three computers. One computer is an AI for learning. One computer is a simulation engine where the AI can learn how to be a robot in a virtual environment, and then also the deployment of it. Everything that moves will be robotic. As we put these robots into the factories, remember, the factories are also robotic. Today's factories are so incredibly complex. This is the NVIDIA AI factory in a digital twin. Gaoxiong is a digital twin. They made Gaoxiong a digital twin. There are already hundreds of thousands of buildings, millions of miles of roads. And so, yes, Gaoxiong is a digital twin. It stands to reason that Taiwan, at the center of the most advanced industry, the epicenter where AI and robotics is going to come from, it stands to reason that this is an extraordinary opportunity for Taiwan. As you know, we have been growing, and all of our partnerships with you have been growing. The number of engineers we have here in Taiwan have been growing. And so we are growing beyond the limits of our current office. And so I'm going to build them a brand new NVIDIA Taiwan office, and it's called NVIDIA Constellation. I'm very pleased to announce that NVIDIA Constellation will be at Beidou Xiling. We are, in fact, creating a whole new industry. This whole new industry is going to expose us to giant opportunities ahead. I look forward to partnering with all of you on building AI factories, agents for enterprises, robots, all of you amazing partners building the ecosystem with us around one architecture. And so I want to thank all of you for coming today. Have a great Computex, everybody. Thank you.